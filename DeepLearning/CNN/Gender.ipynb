{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN  ile ilgili kendimce yazdığım bilgileri ve ilk örnek olan MNIST görevini şu linkten : \n",
    "\n",
    "https://docs.google.com/document/d/1a9qmdJ0WGHwgPTROR2DMa3X1UApmoNzXwVkr-iXbJUA/edit?usp=sharing\n",
    "\n",
    "bulabilirsiniz.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D # resimlerle çalışacağımız için\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN yapısı oluşturma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier= Sequential()\n",
    "\n",
    "classifier.add(Convolution2D(32,3,3,input_shape=(64,64,3),activation=\"relu\")) #32'lik noron ,3,3 kernel size'ını belirtiyoruz.64,64,3'lerin yazmamızın nedeni\n",
    "#64,64'lük resimlerle uğraşıcaz. (istediğimiz boyut bu şekilde.) 3 de katmanı gösteriyor(RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Convolution2D(32,3,3,activation=\"relu\")) #32'lik noron ,3,3 kernel size'ını belirtiyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artifical Neural Network Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(128,activation=\"relu\")) #input layer\n",
    "classifier.add(Dense(1,activation=\"sigmoid\")) #output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "#Derleme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN ve resimler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen= ImageDataGenerator(rescale=1./255,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True) #resimleri alırken bazı uygulamalardan geçirebiliriz. boyutu veya başka şekilde alıp DATA'yı artırabiliriz.\n",
    "\n",
    "#Aynısını şimdi test için yapalım.\n",
    "\n",
    "test_datagen= ImageDataGenerator(rescale=1./255,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resimlerin nasıl yükleneceği.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2662 images belonging to 2 classes.\n",
      "Found 203 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set=train_datagen.flow_from_directory(\"C:/Users/yusuf/Desktop/GOALS/MACHINE LEARNING/Basic/DeepLearning/CNN/training_set\",target_size=(64,64),batch_size=1,class_mode=\"binary\") #class mode 1 veya 0 oluşacağı için.\n",
    "\n",
    "#Aynısını Test için yapalım\n",
    "\n",
    "\n",
    "test_set=test_datagen.flow_from_directory(\"C:/Users/yusuf/Desktop/GOALS/MACHINE LEARNING/Basic/DeepLearning/CNN/test_set\",target_size=(64,64),batch_size=1,class_mode=\"binary\") #class mode 1 veya 0 oluşacağı için."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Stopping (opsiyonel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlyStopping= EarlyStopping(monitor=\"loss\",mode=\"min\",verbose=1,patience=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin öğrenme işlemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "796/800 [============================>.] - ETA: 0s - loss: 0.6096 - accuracy: 0.6646WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
      "800/800 [==============================] - 9s 10ms/step - loss: 0.6097 - accuracy: 0.6650 - val_loss: 0.4949 - val_accuracy: 0.7438\n",
      "Epoch 2/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.5251 - accuracy: 0.7450\n",
      "Epoch 3/150\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.4420 - accuracy: 0.7962\n",
      "Epoch 4/150\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.4510 - accuracy: 0.7738\n",
      "Epoch 5/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.4285 - accuracy: 0.7937\n",
      "Epoch 6/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.4230 - accuracy: 0.7925\n",
      "Epoch 7/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3915 - accuracy: 0.8100\n",
      "Epoch 8/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3682 - accuracy: 0.8213\n",
      "Epoch 9/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3678 - accuracy: 0.8213\n",
      "Epoch 10/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3621 - accuracy: 0.8388\n",
      "Epoch 11/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3629 - accuracy: 0.8188\n",
      "Epoch 12/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3340 - accuracy: 0.8350\n",
      "Epoch 13/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3320 - accuracy: 0.8288\n",
      "Epoch 14/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3137 - accuracy: 0.8425\n",
      "Epoch 15/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3164 - accuracy: 0.8325\n",
      "Epoch 16/150\n",
      "800/800 [==============================] - 8s 9ms/step - loss: 0.3035 - accuracy: 0.8450\n",
      "Epoch 17/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3189 - accuracy: 0.8587\n",
      "Epoch 18/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2963 - accuracy: 0.8637\n",
      "Epoch 19/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3040 - accuracy: 0.8363\n",
      "Epoch 20/150\n",
      "800/800 [==============================] - 8s 9ms/step - loss: 0.2742 - accuracy: 0.8637\n",
      "Epoch 21/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3217 - accuracy: 0.8288\n",
      "Epoch 22/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.3077 - accuracy: 0.8325\n",
      "Epoch 23/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2874 - accuracy: 0.8625\n",
      "Epoch 24/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2786 - accuracy: 0.8500\n",
      "Epoch 25/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2957 - accuracy: 0.8438\n",
      "Epoch 26/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2941 - accuracy: 0.8512\n",
      "Epoch 27/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2609 - accuracy: 0.8788\n",
      "Epoch 28/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2723 - accuracy: 0.8637\n",
      "Epoch 29/150\n",
      "800/800 [==============================] - 8s 9ms/step - loss: 0.2910 - accuracy: 0.8562\n",
      "Epoch 30/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2822 - accuracy: 0.8512\n",
      "Epoch 31/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2765 - accuracy: 0.8612\n",
      "Epoch 32/150\n",
      "800/800 [==============================] - 8s 11ms/step - loss: 0.2446 - accuracy: 0.8737\n",
      "Epoch 33/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2500 - accuracy: 0.8575\n",
      "Epoch 34/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2491 - accuracy: 0.8737\n",
      "Epoch 35/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2416 - accuracy: 0.8825\n",
      "Epoch 36/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2442 - accuracy: 0.8813\n",
      "Epoch 37/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2634 - accuracy: 0.8625\n",
      "Epoch 38/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2768 - accuracy: 0.8575\n",
      "Epoch 39/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2419 - accuracy: 0.8813\n",
      "Epoch 40/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2595 - accuracy: 0.8625\n",
      "Epoch 41/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2442 - accuracy: 0.8775\n",
      "Epoch 42/150\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.2643 - accuracy: 0.8625\n",
      "Epoch 43/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2571 - accuracy: 0.8725\n",
      "Epoch 44/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2645 - accuracy: 0.8750\n",
      "Epoch 45/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2489 - accuracy: 0.8687\n",
      "Epoch 46/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2525 - accuracy: 0.8737\n",
      "Epoch 47/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2321 - accuracy: 0.8938\n",
      "Epoch 48/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2613 - accuracy: 0.8662\n",
      "Epoch 49/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2391 - accuracy: 0.8775\n",
      "Epoch 50/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2363 - accuracy: 0.8650\n",
      "Epoch 51/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2330 - accuracy: 0.8863\n",
      "Epoch 52/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2544 - accuracy: 0.8750\n",
      "Epoch 53/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2325 - accuracy: 0.8800\n",
      "Epoch 54/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2123 - accuracy: 0.8850\n",
      "Epoch 55/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2307 - accuracy: 0.8913\n",
      "Epoch 56/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2098 - accuracy: 0.8925\n",
      "Epoch 57/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2554 - accuracy: 0.8700\n",
      "Epoch 58/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2547 - accuracy: 0.8737\n",
      "Epoch 59/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2095 - accuracy: 0.8988\n",
      "Epoch 60/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2203 - accuracy: 0.8963\n",
      "Epoch 61/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2253 - accuracy: 0.8875\n",
      "Epoch 62/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2436 - accuracy: 0.8750\n",
      "Epoch 63/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2219 - accuracy: 0.8938\n",
      "Epoch 64/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2034 - accuracy: 0.9100\n",
      "Epoch 65/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2328 - accuracy: 0.8750\n",
      "Epoch 66/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2040 - accuracy: 0.8900\n",
      "Epoch 67/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2506 - accuracy: 0.8737\n",
      "Epoch 68/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2120 - accuracy: 0.8863\n",
      "Epoch 69/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2350 - accuracy: 0.8838\n",
      "Epoch 70/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2144 - accuracy: 0.8900\n",
      "Epoch 71/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2229 - accuracy: 0.8938\n",
      "Epoch 72/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2018 - accuracy: 0.8800\n",
      "Epoch 73/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2268 - accuracy: 0.8925\n",
      "Epoch 74/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2247 - accuracy: 0.8825\n",
      "Epoch 75/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2133 - accuracy: 0.9062\n",
      "Epoch 76/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1971 - accuracy: 0.8938\n",
      "Epoch 77/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2323 - accuracy: 0.8863\n",
      "Epoch 78/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2007 - accuracy: 0.8963\n",
      "Epoch 79/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2131 - accuracy: 0.8900\n",
      "Epoch 80/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2024 - accuracy: 0.8913\n",
      "Epoch 81/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2155 - accuracy: 0.8825\n",
      "Epoch 82/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2231 - accuracy: 0.8988\n",
      "Epoch 83/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2103 - accuracy: 0.9025\n",
      "Epoch 84/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1929 - accuracy: 0.8975\n",
      "Epoch 85/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.2292 - accuracy: 0.8800\n",
      "Epoch 86/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2064 - accuracy: 0.8963\n",
      "Epoch 87/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2324 - accuracy: 0.8975\n",
      "Epoch 88/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.1981 - accuracy: 0.9100\n",
      "Epoch 89/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2094 - accuracy: 0.8950\n",
      "Epoch 90/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.1975 - accuracy: 0.9050\n",
      "Epoch 91/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2233 - accuracy: 0.8925\n",
      "Epoch 92/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.1956 - accuracy: 0.9075\n",
      "Epoch 93/150\n",
      "800/800 [==============================] - 8s 11ms/step - loss: 0.2043 - accuracy: 0.8913\n",
      "Epoch 94/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2070 - accuracy: 0.8975\n",
      "Epoch 95/150\n",
      "800/800 [==============================] - 8s 9ms/step - loss: 0.2248 - accuracy: 0.9025\n",
      "Epoch 96/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2232 - accuracy: 0.8950\n",
      "Epoch 97/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2124 - accuracy: 0.8900\n",
      "Epoch 98/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1957 - accuracy: 0.9125\n",
      "Epoch 99/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1846 - accuracy: 0.9075\n",
      "Epoch 100/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1938 - accuracy: 0.9150\n",
      "Epoch 101/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2140 - accuracy: 0.9075\n",
      "Epoch 102/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2085 - accuracy: 0.8938\n",
      "Epoch 103/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1822 - accuracy: 0.9075\n",
      "Epoch 104/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.1939 - accuracy: 0.8975\n",
      "Epoch 105/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1774 - accuracy: 0.9187\n",
      "Epoch 106/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2063 - accuracy: 0.9062\n",
      "Epoch 107/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2167 - accuracy: 0.8875\n",
      "Epoch 108/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1854 - accuracy: 0.9150\n",
      "Epoch 109/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.1891 - accuracy: 0.8975\n",
      "Epoch 110/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.1903 - accuracy: 0.9000\n",
      "Epoch 111/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.1841 - accuracy: 0.9087\n",
      "Epoch 112/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1917 - accuracy: 0.9137\n",
      "Epoch 113/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1872 - accuracy: 0.9175\n",
      "Epoch 114/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1847 - accuracy: 0.9175\n",
      "Epoch 115/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.1834 - accuracy: 0.9137\n",
      "Epoch 116/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.1955 - accuracy: 0.9087\n",
      "Epoch 117/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.1860 - accuracy: 0.9075\n",
      "Epoch 118/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.1850 - accuracy: 0.9075\n",
      "Epoch 119/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.1885 - accuracy: 0.9150\n",
      "Epoch 120/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.1602 - accuracy: 0.9175\n",
      "Epoch 121/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2047 - accuracy: 0.8900\n",
      "Epoch 122/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2037 - accuracy: 0.8950\n",
      "Epoch 123/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2111 - accuracy: 0.8988\n",
      "Epoch 124/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.2008 - accuracy: 0.9025\n",
      "Epoch 125/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2004 - accuracy: 0.8988\n",
      "Epoch 126/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.2118 - accuracy: 0.8988\n",
      "Epoch 127/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.1610 - accuracy: 0.9200\n",
      "Epoch 128/150\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.1854 - accuracy: 0.9100\n",
      "Epoch 129/150\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 0.2188 - accuracy: 0.9075\n",
      "Epoch 130/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.1966 - accuracy: 0.9087\n",
      "Epoch 131/150\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.1869 - accuracy: 0.9013\n",
      "Epoch 132/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1919 - accuracy: 0.9038\n",
      "Epoch 133/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1752 - accuracy: 0.9200\n",
      "Epoch 134/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1795 - accuracy: 0.9150\n",
      "Epoch 135/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1807 - accuracy: 0.9150\n",
      "Epoch 136/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1830 - accuracy: 0.9187\n",
      "Epoch 137/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1819 - accuracy: 0.9087\n",
      "Epoch 138/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1907 - accuracy: 0.9013\n",
      "Epoch 139/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1932 - accuracy: 0.9137\n",
      "Epoch 140/150\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1714 - accuracy: 0.9225\n",
      "Epoch 141/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1945 - accuracy: 0.9212\n",
      "Epoch 142/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1735 - accuracy: 0.9137\n",
      "Epoch 143/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1752 - accuracy: 0.9162\n",
      "Epoch 144/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1936 - accuracy: 0.9087\n",
      "Epoch 145/150\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1858 - accuracy: 0.9112\n",
      "Epoch 145: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x230378c05e0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(training_set,steps_per_epoch=800,epochs=150,validation_data=(test_set),validation_steps=2000,callbacks=[earlyStopping])\n",
    "#Stepes_per_epoch=her epoch'ta kaç veri okunacağı =batch size\n",
    "#nb_val_samples keyword coded as validation_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kodu bir daha çalıştırırsak üstüne öğrenir onun önüne geçmek için..\n",
    " Ve tahminleri görmek için."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/203 [..............................] - ETA: 22s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-84-98aef240162d>:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred=classifier.predict_generator(test_set,verbose=1) #verbose nasıl çalıştığını göstermek için\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.7915472e-05],\n",
       "       [8.9675406e-05],\n",
       "       [9.0298057e-04],\n",
       "       [3.2553077e-04],\n",
       "       [2.7900243e-01],\n",
       "       [1.1334854e-06],\n",
       "       [6.6624416e-08],\n",
       "       [3.2610542e-06],\n",
       "       [6.7961323e-01],\n",
       "       [4.5992130e-01],\n",
       "       [1.3832569e-02],\n",
       "       [5.0904895e-05],\n",
       "       [1.5303493e-04],\n",
       "       [4.9643591e-01],\n",
       "       [4.0253848e-01],\n",
       "       [9.9355959e-05],\n",
       "       [2.3267672e-05],\n",
       "       [2.8645205e-01],\n",
       "       [1.5160441e-04],\n",
       "       [2.7680856e-01],\n",
       "       [6.5946579e-04],\n",
       "       [1.5814706e-07],\n",
       "       [4.1967411e-07],\n",
       "       [6.7217118e-01],\n",
       "       [2.3055077e-04],\n",
       "       [1.5907855e-05],\n",
       "       [4.1815041e-05],\n",
       "       [3.7305504e-02],\n",
       "       [3.5875325e-06],\n",
       "       [1.3042935e-05],\n",
       "       [1.9361007e-01],\n",
       "       [4.9840435e-01],\n",
       "       [3.0275163e-07],\n",
       "       [1.6990304e-04],\n",
       "       [4.0639469e-01],\n",
       "       [2.6326330e-07],\n",
       "       [2.2342281e-06],\n",
       "       [2.2591731e-01],\n",
       "       [3.3655077e-01],\n",
       "       [3.2026243e-01],\n",
       "       [9.2399794e-05],\n",
       "       [3.6558318e-01],\n",
       "       [2.6019979e-06],\n",
       "       [8.5655046e-01],\n",
       "       [1.6927123e-01],\n",
       "       [5.4945995e-06],\n",
       "       [8.7380409e-04],\n",
       "       [4.1305423e-03],\n",
       "       [1.4185739e-06],\n",
       "       [1.6433001e-04],\n",
       "       [1.7738938e-03],\n",
       "       [9.6538663e-04],\n",
       "       [5.2274251e-01],\n",
       "       [5.6544244e-02],\n",
       "       [2.0835102e-03],\n",
       "       [1.8936396e-04],\n",
       "       [5.4477924e-01],\n",
       "       [1.2293964e-05],\n",
       "       [1.2406379e-02],\n",
       "       [4.6589365e-05],\n",
       "       [2.2156364e-06],\n",
       "       [1.6459961e-05],\n",
       "       [4.5499206e-04],\n",
       "       [2.1791435e-05],\n",
       "       [2.1532813e-05],\n",
       "       [3.3544964e-07],\n",
       "       [3.2500327e-03],\n",
       "       [1.8446204e-05],\n",
       "       [9.1884428e-01],\n",
       "       [6.1350763e-03],\n",
       "       [5.3216690e-01],\n",
       "       [1.3965368e-04],\n",
       "       [1.1613816e-06],\n",
       "       [4.5049191e-04],\n",
       "       [1.0210124e-06],\n",
       "       [8.3606556e-06],\n",
       "       [2.1609664e-04],\n",
       "       [5.3184813e-01],\n",
       "       [9.4594825e-06],\n",
       "       [8.6526275e-03],\n",
       "       [2.2595244e-05],\n",
       "       [6.1133258e-05],\n",
       "       [9.2459733e-05],\n",
       "       [9.0599140e-05],\n",
       "       [7.7634549e-01],\n",
       "       [7.7115238e-01],\n",
       "       [1.7881393e-04],\n",
       "       [5.0920794e-06],\n",
       "       [3.6571571e-01],\n",
       "       [9.1791153e-04],\n",
       "       [1.5900469e-01],\n",
       "       [2.2843120e-01],\n",
       "       [2.4257302e-01],\n",
       "       [3.3815894e-01],\n",
       "       [3.6191940e-04],\n",
       "       [1.8442158e-07],\n",
       "       [5.2049163e-06],\n",
       "       [4.5144558e-04],\n",
       "       [1.9482374e-03],\n",
       "       [1.8836084e-01],\n",
       "       [6.7062096e-08],\n",
       "       [2.7544969e-08],\n",
       "       [2.1556996e-05],\n",
       "       [2.3408318e-01],\n",
       "       [4.6485230e-01],\n",
       "       [5.1696688e-01],\n",
       "       [8.2947895e-07],\n",
       "       [4.2796883e-06],\n",
       "       [1.1345446e-03],\n",
       "       [5.4208332e-01],\n",
       "       [3.1717420e-05],\n",
       "       [3.6311150e-03],\n",
       "       [4.6516395e-01],\n",
       "       [9.1879344e-01],\n",
       "       [9.1076565e-01],\n",
       "       [5.2249788e-06],\n",
       "       [1.3538748e-06],\n",
       "       [1.0672871e-05],\n",
       "       [6.4172989e-01],\n",
       "       [9.4843709e-01],\n",
       "       [2.9473275e-01],\n",
       "       [4.4904820e-07],\n",
       "       [1.8876672e-02],\n",
       "       [4.7645491e-01],\n",
       "       [1.0080338e-03],\n",
       "       [1.1996365e-05],\n",
       "       [6.6724540e-05],\n",
       "       [4.6687108e-01],\n",
       "       [8.4190565e-01],\n",
       "       [1.2796151e-07],\n",
       "       [9.7298622e-04],\n",
       "       [1.1747087e-04],\n",
       "       [1.3015866e-03],\n",
       "       [1.1519388e-05],\n",
       "       [2.0706654e-04],\n",
       "       [1.5804172e-04],\n",
       "       [6.9268197e-02],\n",
       "       [1.9946694e-04],\n",
       "       [2.3040544e-05],\n",
       "       [5.1248741e-01],\n",
       "       [1.2190185e-05],\n",
       "       [3.9302995e-05],\n",
       "       [5.1684231e-01],\n",
       "       [6.0835481e-04],\n",
       "       [5.9557509e-01],\n",
       "       [2.3897517e-01],\n",
       "       [5.9345365e-04],\n",
       "       [5.6409836e-04],\n",
       "       [1.4463625e-06],\n",
       "       [4.1191853e-07],\n",
       "       [9.7070944e-01],\n",
       "       [1.0462717e-05],\n",
       "       [3.4414837e-01],\n",
       "       [3.1737313e-06],\n",
       "       [4.3268062e-07],\n",
       "       [1.4067179e-07],\n",
       "       [1.4500466e-05],\n",
       "       [2.3982264e-05],\n",
       "       [2.0610989e-05],\n",
       "       [1.9359589e-04],\n",
       "       [1.2626797e-01],\n",
       "       [9.8791718e-04],\n",
       "       [2.4002254e-02],\n",
       "       [5.1277044e-07],\n",
       "       [5.3476393e-03],\n",
       "       [5.7965469e-01],\n",
       "       [6.1413646e-04],\n",
       "       [6.0586882e-01],\n",
       "       [7.3785204e-06],\n",
       "       [4.5849884e-01],\n",
       "       [8.7324679e-03],\n",
       "       [1.4510155e-03],\n",
       "       [7.4951008e-06],\n",
       "       [5.3127170e-01],\n",
       "       [9.7241998e-04],\n",
       "       [3.0809701e-05],\n",
       "       [3.0517721e-01],\n",
       "       [3.9142802e-01],\n",
       "       [1.1732425e-05],\n",
       "       [1.2630075e-02],\n",
       "       [1.4500245e-07],\n",
       "       [3.8878974e-05],\n",
       "       [8.5004969e-05],\n",
       "       [6.8975985e-03],\n",
       "       [5.2284861e-01],\n",
       "       [2.1583945e-05],\n",
       "       [1.6905576e-02],\n",
       "       [2.0574012e-01],\n",
       "       [6.9960296e-02],\n",
       "       [1.6331673e-04],\n",
       "       [5.7421657e-05],\n",
       "       [4.9276482e-06],\n",
       "       [7.0169568e-04],\n",
       "       [5.8740975e-06],\n",
       "       [3.3234328e-01],\n",
       "       [4.3108138e-01],\n",
       "       [1.6316772e-04],\n",
       "       [3.7963688e-03],\n",
       "       [6.1814717e-05],\n",
       "       [2.3052096e-04],\n",
       "       [5.2902544e-01],\n",
       "       [1.0732889e-02],\n",
       "       [3.6015838e-02]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.reset()\n",
    "pred=classifier.predict_generator(test_set,verbose=1) #verbose nasıl çalıştığını göstermek için\n",
    "\n",
    "\n",
    "pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bize net değer döndürmicek 0.2 gibi değerler döndürücek. Onun önüne geçmek için. Bir elekten geçirmem şart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[pred>0.5] =1\n",
    "pred[pred<=0.5] =0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi de bunu Confusion Matrix'e hazır hale getirmemiz lazım bu yüzden veriyle oynamamız gerekiyor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels=[] # test'leriyle aldığım verileri (bunu y_test olarak düşünebiliriz) karşılaştırma yapıcam.\n",
    "#bunun için bir döngü kurdum.\n",
    "for i in range(0,int(203)):\n",
    "    test_labels.extend(np.array(test_set[i][1]))\n",
    "\n",
    "test_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bunu da hallettikten sonra Confusion Matrix'de doğruluğu alalım.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[129,  22],\n",
       "       [ 48,   4]], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm= confusion_matrix(test_labels,pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir başka karşılaştırma yöntemi ise. Filenames'leri alıp predictlerle karşılaştırmak.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dosyaisimleri</th>\n",
       "      <th>tahminler</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>erkek\\AbdA_00001_m_31_i_fr_nc_no_2016_2_e0_nl_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>erkek\\AbdA_00002_m_31_i_fr_nc_sr_2016_2_e0_nl_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erkek\\AbdA_00003_m_31_i_fr_nc_hp_2016_2_e0_nl_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>erkek\\AbdA_00004_m_31_i_fr_nc_hp_2016_2_e0_nl_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>erkek\\AbdA_00005_m_31_i_fr_nc_hp_2016_2_e0_nl_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>kadin\\HadM_00817_f_23_i_nf_nc_hp_2014_1_e0_nl_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>kadin\\HadM_00818_f_25_o_nf_nc_no_2016_1_e0_nl_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>kadin\\HadM_00819_f_25_o_nf_nc_no_2016_1_e0_nl_...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>kadin\\HebD_00821_f_28_i_nf_cr_sd_2016_1_e0_nl_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>kadin\\HebD_00822_f_28_o_nf_nc_hp_2016_1_e0_nl_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         dosyaisimleri  tahminler  test\n",
       "0    erkek\\AbdA_00001_m_31_i_fr_nc_no_2016_2_e0_nl_...        0.0   0.0\n",
       "1    erkek\\AbdA_00002_m_31_i_fr_nc_sr_2016_2_e0_nl_...        0.0   0.0\n",
       "2    erkek\\AbdA_00003_m_31_i_fr_nc_hp_2016_2_e0_nl_...        0.0   0.0\n",
       "3    erkek\\AbdA_00004_m_31_i_fr_nc_hp_2016_2_e0_nl_...        0.0   1.0\n",
       "4    erkek\\AbdA_00005_m_31_i_fr_nc_hp_2016_2_e0_nl_...        0.0   0.0\n",
       "..                                                 ...        ...   ...\n",
       "198  kadin\\HadM_00817_f_23_i_nf_nc_hp_2014_1_e0_nl_...        0.0   1.0\n",
       "199  kadin\\HadM_00818_f_25_o_nf_nc_no_2016_1_e0_nl_...        0.0   0.0\n",
       "200  kadin\\HadM_00819_f_25_o_nf_nc_no_2016_1_e0_nl_...        1.0   0.0\n",
       "201  kadin\\HebD_00821_f_28_i_nf_cr_sd_2016_1_e0_nl_...        0.0   0.0\n",
       "202  kadin\\HebD_00822_f_28_o_nf_nc_hp_2016_1_e0_nl_...        0.0   0.0\n",
       "\n",
       "[203 rows x 3 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dosyaisimleri=test_set.filenames\n",
    "\n",
    "sonuc=pd.DataFrame()\n",
    "sonuc[\"dosyaisimleri\"]=dosyaisimleri\n",
    "sonuc[\"tahminler\"]=pred\n",
    "sonuc[\"test\"]=test_labels\n",
    "\n",
    "sonuc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e26da9777431fcd98778416b583e2cb3f0c4f5515b7897587b203af2bddddd45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
